{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "74a067df-3897-4ce5-a8c8-7dad0d631308",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import socket\n",
    "import pprint\n",
    "import argparse\n",
    "\n",
    "from anytree import Node\n",
    "from lib.helpers import load_ip_to_as_mapping, load_config_file, load_hypergiant_ases, process_configuration_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "44f06195-8f56-4a1b-8733-6ebaf0ee6ff5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_tld_suffixes(file_path_suffixes=\"../datasets/tld_suffixes/suffixes.txt\"):\n",
    "    suffixes = dict()\n",
    "    try:\n",
    "        with open(file_path_suffixes, 'rt') as f:\n",
    "            for line in f:\n",
    "                if \"!\" in line or \"//\" in line:\n",
    "                    continue\n",
    "                if line[0] == \"*\":\n",
    "                    suffixes[line[2:].rstrip()] = None\n",
    "                else:\n",
    "                    suffixes[line.rstrip()] = None\n",
    "    except:\n",
    "        print(\"Couldn't load/process TLD suffixes file \\\"{}\\\"\".format(file_path_suffixes))\n",
    "        return None\n",
    "    return suffixes\n",
    "\n",
    "\n",
    "def is_hostname(dns_name):\n",
    "    try:\n",
    "        socket.inet_aton(dns_name)\n",
    "        return False\n",
    "    except socket.error as e:\n",
    "        return True\n",
    "\n",
    "\n",
    "def createFilePaths(filePathToStoreResults):\n",
    "    if not os.path.exists(filePathToStoreResults):\n",
    "        os.makedirs(filePathToStoreResults)\n",
    "\n",
    "\n",
    "def calc_TLD_plus_one(dns_name, suffixes):\n",
    "    dns_name = dns_name.lstrip('*.')\n",
    "    if '/' in dns_name:\n",
    "        dns_name = dns_name.replace('/', '')\n",
    "    # If not a valid dns_name skip it\n",
    "    if '.' not in dns_name:\n",
    "        return None, None\n",
    "    # Split domain name to parts\n",
    "    domain_name_fragmented = dns_name.split('.')\n",
    "    # Construct TLD+1 key (e.g '.google.com' -> 'com.google')\n",
    "    tld_plus_one = domain_name_fragmented[-1] + '.' + domain_name_fragmented[-2]\n",
    "    tld_plus_one_check_suffix = domain_name_fragmented[-2] + '.' + domain_name_fragmented[-1]\n",
    "    if tld_plus_one_check_suffix in suffixes:\n",
    "        if len(domain_name_fragmented) > 3:\n",
    "            tld_plus_one = domain_name_fragmented[-1] + '.' + domain_name_fragmented[-2] + '.' + domain_name_fragmented[-3]\n",
    "            domain_name_fragmented[-2] = domain_name_fragmented[-1] + '.' + domain_name_fragmented[-2]\n",
    "            del domain_name_fragmented[-1]\n",
    "        else:\n",
    "            return None, None\n",
    "\n",
    "    return tld_plus_one, domain_name_fragmented\n",
    "\n",
    "\n",
    "def generate_on_net_fingerprints(on_net_folder, suffixes):\n",
    "    files = os.listdir(on_net_folder)\n",
    "    dns_names_per_hg = dict()\n",
    "    if on_net_folder[-1] != '/':\n",
    "        on_net_folder += '/'\n",
    "    for file in files:\n",
    "        if '.txt' in file:\n",
    "            hg_keyword = file.split('.')[0]\n",
    "            if  hg_keyword not in dns_names_per_hg:\n",
    "                dns_names_per_hg[hg_keyword] = dict()\n",
    "\n",
    "            with open(on_net_folder + file, 'rt') as f:\n",
    "                for line in f:\n",
    "                    data = json.loads(line)\n",
    "                    if 'dns_names' in data:\n",
    "                        for dns_name in data['dns_names']:\n",
    "                            if is_hostname(dns_name):\n",
    "                            # Exclude cases where dns_name is not a hostname but an IP\n",
    "                                tld_plus_one, domain_name_fragmented = calc_TLD_plus_one(dns_name, suffixes)\n",
    "                                dns_names_per_hg[hg_keyword][tld_plus_one] = None\n",
    "    return dns_names_per_hg\n",
    "\n",
    "\n",
    "def process_off_nets(ee_certs_file, ip_to_as, dns_names_per_hg, hg_asn_to_hg_keywords, tld_suffixes, filePathToStoreResults):\n",
    "    openFiles_l = dict()\n",
    "    hg_keywords_l = {v for v_list in hg_asn_to_hg_keywords.values() for v in v_list}\n",
    "    for hg_keyword in hg_keywords_l:\n",
    "        filePath = filePathToStoreResults + hg_keyword + \".txt\"\n",
    "        openFiles_l[hg_keyword] = open(filePath, 'wt')\n",
    "\n",
    "    \n",
    "    with open(ee_certs_file, 'rt') as f:\n",
    "        # Load lines in ee_certs.txt file\n",
    "        for line in f:\n",
    "            data = json.loads(line)\n",
    "            # Go over every IP in the ee_certs.txt file\n",
    "            for ip in data:\n",
    "                asns = []\n",
    "                try:\n",
    "                    # Capture all ASNs associated to the IP\n",
    "                    asns = ip_to_as[ip]\n",
    "                except:\n",
    "                    pass\n",
    "\n",
    "            if len(asns) > 0:\n",
    "                # Check if subject and organization fields are present in the certificate\n",
    "                if 'subject' in data[ip]:\n",
    "                    if 'organization' in data[ip]['subject']:\n",
    "                        organization_value = \"\"\n",
    "                        for item in data[ip]['subject']['organization']:\n",
    "                            if item is not None:\n",
    "                                organization_value += item.lower() + \" \"\n",
    "                        for hg_keyword in hg_keywords_l:\n",
    "                            # Check if a hg_keyword is in the organization field\n",
    "                            if hg_keyword in organization_value:\n",
    "                                #Check if it is  an on-net of hypergiant\n",
    "                                is_on_net = False\n",
    "                                for asn in asns:\n",
    "                                    # Check ASN \n",
    "                                    if asn in hg_asn_to_hg_keywords:\n",
    "                                        # Check if hg_keyword is in hg_keywords of the ASN\n",
    "                                        if hg_keyword in hg_asn_to_hg_keywords[asn]:\n",
    "                                            is_on_net = True\n",
    "\n",
    "                                if is_on_net == False:\n",
    "                                    allDNS_names_match = True # Fixed coding mistake, used to be in the loop below thus only checking last dns_name\n",
    "                                    # Check if all dns names of certificate are present in the set of known on-net dns names\n",
    "                                    for dns_name in data[ip]['dns_names']:\n",
    "                                        tld_plus_one, domain_name_fragmented = calc_TLD_plus_one(dns_name, tld_suffixes)\n",
    "                                        if tld_plus_one not in dns_names_per_hg[hg_keyword]:\n",
    "                                            allDNS_names_match = False\n",
    "                                            \n",
    "                                    # When all dns names match we can save the candidate off-net\n",
    "                                    if allDNS_names_match == True:\n",
    "                                        storeJSON = { \n",
    "                                                    \"ip\" : ip,\n",
    "                                                    \"ASN\" : asns[0],\n",
    "                                                    \"dns_names\" : data[ip]['dns_names'],\n",
    "                                                    \"subject:organization\" : organization_value\n",
    "                                                    }\n",
    "                                        openFiles_l[hg_keyword].write(\"{}\\n\".format(json.dumps(storeJSON)))\n",
    "    for file in openFiles_l:\n",
    "        openFiles_l[file].close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "26483412-f4f0-4356-b117-a14c370d415c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!\n"
     ]
    }
   ],
   "source": [
    "hg_ases_file = \"../datasets/hypergiants/2019_11_hypergiants_asns.json\"\n",
    "ee_certs_file = \"./results/ee_certs.txt\"\n",
    "config_file = \"./configs/config.txt\"\n",
    "ip2as_file = \"../datasets/ip_to_as/2019_11_25thres_db.json\"\n",
    "on_net_dir = \"./results/on-nets/\"\n",
    "\n",
    "# Store results in specified path\n",
    "result_path = \"./results/candidate_off-nets_bad/\"\n",
    "\n",
    "# Suffixes extracted from:  https://publicsuffix.org\n",
    "tld_suffixes = load_tld_suffixes()\n",
    "\n",
    "# Load the IP-to-AS mapping\n",
    "ip_to_as = load_ip_to_as_mapping(ip2as_file)\n",
    "\n",
    "# Load the Hypergiant ASes\n",
    "hg_ases = load_hypergiant_ases(hg_ases_file)\n",
    "\n",
    "# Load the config file\n",
    "configuration_input = load_config_file(config_file)\n",
    "\n",
    "# Check if config file is valid and return a map between HG ASes and HG keywords\n",
    "hg_asn_to_hg_keywords = process_configuration_file(configuration_input, hg_ases)\n",
    "\n",
    "dns_names_per_hg = generate_on_net_fingerprints(on_net_dir, tld_suffixes)\n",
    "\n",
    "# Find the Off-nets of each HG\n",
    "process_off_nets(ee_certs_file, ip_to_as, dns_names_per_hg, hg_asn_to_hg_keywords, tld_suffixes, result_path)\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a93c5d92-8d93-48d8-bf4a-2effaa9de916",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
